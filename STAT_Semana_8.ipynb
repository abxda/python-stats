{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9nyu8ui8a61TROOEQsxZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/python-stats/blob/main/STAT_Semana_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Muestras y Poblaciones\n",
        "**Descripción:**\n",
        "\n",
        "- **Definición de población y muestra**: La población es el conjunto total de elementos que se desea estudiar, mientras que la muestra es un subconjunto representativo de la población.\n",
        "- **Diferencias entre parámetros muestrales y poblacionales**: Los parámetros muestrales se calculan a partir de la muestra y se utilizan para estimar los parámetros poblacionales.\n",
        "- **Importancia del muestreo en la inferencia estadística**: El muestreo permite hacer inferencias sobre la población sin necesidad de examinar a todos sus miembros.\n",
        "- **Ejemplos de cómo se utilizan las muestras para estimar valores poblacionales**: A través de la media muestral, varianza muestral, etc.\n",
        "\n",
        "**Código Python:**"
      ],
      "metadata": {
        "id": "EnMqEClbF8_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "806XfTAvEiBp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generar una población\n",
        "mu = 50\n",
        "sigma = 10\n",
        "poblacion = np.random.normal(mu,sigma, size=10000)\n",
        "\n",
        "# Obtener una muestra aleatoria de la población\n",
        "muestra = np.random.choice(poblacion, size=100, replace=False)\n",
        "\n",
        "# Calcular la media muestral\n",
        "media_muestral = np.mean(muestra)\n",
        "\n",
        "# Calcular la media poblacional\n",
        "media_poblacional = np.mean(poblacion)\n",
        "\n",
        "print(f\"Media muestral: {media_muestral}\")\n",
        "print(f\"Media poblacional: {media_poblacional}\")\n",
        "\n",
        "# Visualizar la distribución de la población y la muestra\n",
        "plt.hist(poblacion, bins=20, alpha=0.5, label='Población')\n",
        "plt.hist(muestra, bins=20, alpha=0.5, label='Muestra')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Valores')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución de la población y la muestra')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferencia y Estimación Puntual\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "#### Definición de inferencia estadística:\n",
        "La inferencia estadística es el proceso de deducir propiedades de una población a partir de una muestra de datos tomada de esa población. Este proceso nos permite hacer afirmaciones sobre la población completa sin tener que examinar a todos sus miembros. Por ejemplo, si queremos saber la altura promedio de los adultos en una ciudad, no necesitamos medir a cada adulto. En su lugar, podemos medir una muestra representativa y usar inferencia estadística para estimar la altura promedio de la población.\n",
        "\n",
        "#### Introducción al concepto de estimador y estimación puntual:\n",
        "Un estimador es una regla o fórmula que usamos para calcular una estimación de un parámetro poblacional basado en una muestra. La estimación puntual es el valor específico que obtenemos usando ese estimador. Por ejemplo, si usamos la media muestral ($\\bar{x}$) para estimar la media poblacional ($\\mu$), $\\bar{x}$ es el estimador y el valor específico de $\\bar{x}$ que calculamos a partir de una muestra es la estimación puntual.\n",
        "\n",
        "#### Ejemplo intuitivo:\n",
        "Imagina que quieres saber el promedio de caramelos en las bolsas producidas en una fábrica. En lugar de abrir todas las bolsas, tomas una muestra aleatoria de 10 bolsas, cuentas los caramelos en cada una y calculas el promedio de esos 10 valores. Este promedio es tu estimación puntual del promedio de caramelos en todas las bolsas.\n",
        "\n",
        "#### Estimador de máxima verosimilitud para la media poblacional:\n",
        "El estimador de máxima verosimilitud es un método común para estimar parámetros poblacionales. Para la media poblacional ($\\mu$), el estimador de máxima verosimilitud es simplemente la media muestral ($\\bar{x}$). Esto significa que calculamos la media de los valores en nuestra muestra y la usamos como la mejor estimación de la media de la población.\n",
        "\n",
        "#### Ejemplo intuitivo:\n",
        "Si tomas una muestra de 10 estudiantes y calculas su calificación promedio en un examen, esa calificación promedio es tu mejor estimación de la calificación promedio de todos los estudiantes que tomaron el examen.\n",
        "\n",
        "#### Estimación insesgada para la varianza poblacional:\n",
        "La varianza mide la dispersión de los datos alrededor de la media. Para estimar la varianza poblacional ($\\sigma^2$), usamos la cuasivarianza muestral. Esto se debe a que dividir por $n-1$ en lugar de $n$ (donde $n$ es el tamaño de la muestra) proporciona una estimación más precisa. Esta corrección se llama corrección de Bessel.\n",
        "\n",
        "#### Fórmula:\n",
        "Si $x_1, x_2, \\ldots, x_n$ son los valores de una muestra y $\\bar{x}$ es la media muestral, la cuasivarianza muestral (s^2) se calcula como:\n",
        "$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $\n",
        "\n",
        "#### Ejemplo intuitivo:\n",
        "Imagina que tienes 5 mediciones de temperatura en un día: 18, 20, 19, 21 y 20 grados. Primero, calculas la media de estas mediciones. Luego, calculas la diferencia entre cada medición y la media, las elevas al cuadrado, sumas estos valores y finalmente divides por $n-1$ para obtener la varianza muestral.\n",
        "\n",
        "### Resumen de Conceptos:\n",
        "\n",
        "1. **Inferencia Estadística**: Nos permite hacer afirmaciones sobre una población basándonos en una muestra.\n",
        "2. **Estimador y Estimación Puntual**: Un estimador es una fórmula usada para calcular una estimación. La estimación puntual es el valor específico obtenido usando el estimador.\n",
        "3. **Estimador de Máxima Verosimilitud**: La media muestral ($\\bar{x}$) es el estimador de máxima verosimilitud para la media poblacional ($\\mu$).\n",
        "4. **Estimación Insesgada de la Varianza**: La cuasivarianza muestral (s^2) se usa para estimar la varianza poblacional ($\\sigma^2$), proporcionando una estimación más precisa que dividir por $n$.\n",
        "**Código Python:**\n"
      ],
      "metadata": {
        "id": "0SR2UOkfLpbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar una muestra\n",
        "mu = 50\n",
        "sigma = 10\n",
        "muestra = np.random.normal(mu,sigma, size=100)\n",
        "\n",
        "# Calcular la media muestral (estimador de la media poblacional)\n",
        "media_muestral = np.mean(muestra)\n",
        "\n",
        "# Calcular la cuasivarianza muestral (estimador insesgado de la varianza poblacional)\n",
        "cuasivarianza_muestral = np.var(muestra, ddof=1)\n",
        "\n",
        "print(f\"Estimación de la media poblacional: {media_muestral}\")\n",
        "print(f\"Estimación de la varianza poblacional: {cuasivarianza_muestral}\")"
      ],
      "metadata": {
        "id": "nqMqf6tqLADE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esperanza Matemática\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "#### Definición de esperanza matemática:\n",
        "La esperanza matemática, también conocida como valor esperado, es una medida de la centralidad de una distribución de probabilidad. Se puede entender como el promedio ponderado de todos los posibles valores que puede tomar una variable aleatoria, donde cada valor está ponderado por su probabilidad de ocurrencia. Es un concepto fundamental en la teoría de la probabilidad y la estadística, ya que proporciona una medida del \"centro\" de la distribución.\n",
        "\n",
        "#### Interpretación de la esperanza matemática como el valor esperado de una variable aleatoria:\n",
        "La interpretación intuitiva de la esperanza matemática es que representa el valor promedio que se espera obtener si se repite un experimento aleatorio un gran número de veces. Por ejemplo, si lanzas una moneda justa muchas veces, la esperanza matemática del número de caras es el número total de lanzamientos multiplicado por la probabilidad de obtener cara en cada lanzamiento (que es 0.5).\n"
      ],
      "metadata": {
        "id": "tEDmKaGKPWNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Definir una variable aleatoria normal con media (mu) y desviación estándar (sigma)\n",
        "mu = 50\n",
        "sigma = 10\n",
        "X = norm(mu, sigma)\n",
        "\n",
        "# Calcular la esperanza matemática de X\n",
        "# Para una distribución normal, la esperanza matemática es igual a la media (mu)\n",
        "esperanza_X = X.expect()\n",
        "\n",
        "print(f\"Esperanza matemática de X: {esperanza_X}\")\n",
        "\n",
        "# Visualizar la función de densidad de probabilidad (PDF) de X\n",
        "# Generar un rango de valores de x desde el percentil 1% hasta el 99% de la distribución\n",
        "x = np.linspace(X.ppf(0.01), X.ppf(0.99), 100)\n",
        "\n",
        "# Calcular la PDF para cada valor de x\n",
        "pdf_values = X.pdf(x)\n",
        "\n",
        "# Crear la gráfica\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, pdf_values, 'r-', lw=2, alpha=0.6, label='Densidad de probabilidad (PDF)')\n",
        "\n",
        "# Dibujar una línea vertical en el valor de la esperanza matemática\n",
        "plt.axvline(esperanza_X, color='b', linestyle='dashed', linewidth=2, label='Esperanza matemática')\n",
        "\n",
        "# Añadir etiquetas y leyenda\n",
        "plt.xlabel('Valores')\n",
        "plt.ylabel('Densidad de Probabilidad')\n",
        "plt.title('Función de Densidad de Probabilidad de una Distribución Normal')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2loW3lVBNffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos de Mixtura\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Introducción a los modelos de mixtura**: Los modelos de mixtura son modelos probabilísticos que representan una población que puede estar compuesta por varias subpoblaciones, cada una con su propia distribución de probabilidad.\n",
        "- **Aplicaciones de los modelos de mixtura para identificar subpoblaciones dentro de una población**: Los modelos de mixtura se utilizan en diversas áreas como la biología, la economía y la ingeniería para identificar y analizar subgrupos dentro de una población global.\n",
        "- **Ejemplos de modelos de mixtura con distribuciones normales**: En muchos casos, se asume que las subpoblaciones siguen distribuciones normales, lo que facilita la identificación de estas subpoblaciones mediante modelos de mixtura gaussiana.\n",
        "\n",
        "**Código Python:**"
      ],
      "metadata": {
        "id": "_YdIoI65P2wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Generar datos de dos subpoblaciones normales\n",
        "mu1 = 20\n",
        "sigma1 = 5\n",
        "mu2 = 80\n",
        "sigma2 = 10\n",
        "X1 = np.random.normal(mu1, sigma1, size=100)\n",
        "X2 = np.random.normal(mu2, sigma2, size=100)\n",
        "X = np.concatenate((X1, X2))\n",
        "\n",
        "# Ajustar un modelo de mixtura gaussiana con dos componentes\n",
        "modelo = GaussianMixture(n_components=2)\n",
        "modelo.fit(X.reshape(-1, 1))\n",
        "\n",
        "# Obtener las etiquetas de las subpoblaciones\n",
        "etiquetas = modelo.predict(X.reshape(-1, 1))\n",
        "\n",
        "# Visualizar los datos con las etiquetas de las subpoblaciones\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(X, bins=30, alpha=0.5, label='Datos observados', density=True)\n",
        "\n",
        "# Generar valores para las campanas subyacentes\n",
        "x = np.linspace(np.min(X), np.max(X), 1000)\n",
        "logprob = modelo.score_samples(x.reshape(-1, 1))\n",
        "responsibilities = modelo.predict_proba(x.reshape(-1, 1))\n",
        "pdf_individual = responsibilities * np.exp(logprob[:, np.newaxis])\n",
        "pdf = pdf_individual.sum(1)\n",
        "\n",
        "# Visualizar las campanas de las subpoblaciones\n",
        "plt.plot(x, pdf, '-k', label='Mixtura Gaussiana')\n",
        "plt.plot(x, pdf_individual[:, 0], '--', label='Componente 1')\n",
        "plt.plot(x, pdf_individual[:, 1], '--', label='Componente 2')\n",
        "\n",
        "# Añadir puntos muestreados coloreados según las etiquetas\n",
        "colors = ['red', 'black']\n",
        "for label in np.unique(etiquetas):\n",
        "    plt.scatter(X[etiquetas == label], np.zeros_like(X[etiquetas == label]),\n",
        "                c=colors[label], label=f'Subpoblación {label + 1}', s=50, zorder=3)\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Valores')\n",
        "plt.ylabel('Densidad de probabilidad')\n",
        "plt.title('Modelo de Mixtura Gaussiana con Subpoblaciones')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_02QYGGPfnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering (Agrupamiento)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Introducción al clustering**: El clustering es una técnica de análisis de datos que busca agrupar un conjunto de objetos en subgrupos (clusters) de tal manera que los objetos en el mismo grupo (cluster) sean más similares entre sí que con los objetos de otros grupos.\n",
        "- **Diferentes tipos de algoritmos de clustering**:\n",
        "  - **K-means**: Un algoritmo que particiona los datos en K clusters, minimizando la variabilidad dentro de cada cluster.\n",
        "  - **Clustering jerárquico**: Construye una jerarquía de clusters que pueden ser visualizados mediante un dendrograma.\n",
        "  - **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: Agrupa puntos que están juntos en regiones de alta densidad y puede identificar outliers.\n",
        "- **Aplicaciones del clustering en diferentes áreas**: El clustering se utiliza ampliamente en marketing (segmentación de clientes), biología (clasificación de especies), biblioteconomía (organización de libros), imagenología médica (detección de estructuras), entre otros.\n",
        "\n",
        "**Ejemplo de Clustering con K-means en Python:**\n",
        "\n"
      ],
      "metadata": {
        "id": "tR8Jf-FDUXxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Generar datos de tres subpoblaciones normales bidimensionales\n",
        "mu1 = [7, 7]\n",
        "sigma1 = [[1, 0.5], [0.5, 1]]\n",
        "mu2 = [8, 8]\n",
        "sigma2 = [[1, -0.5], [-0.5, 1]]\n",
        "mu3 = [5, 10]\n",
        "sigma3 = [[1, 0.5], [0.5, 1]]\n",
        "\n",
        "X1 = np.random.multivariate_normal(mu1, sigma1, 100)\n",
        "X2 = np.random.multivariate_normal(mu2, sigma2, 100)\n",
        "X3 = np.random.multivariate_normal(mu3, sigma3, 100)\n",
        "X = np.concatenate((X1, X2, X3))\n",
        "\n",
        "# Ajustar un modelo k-means con tres clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Obtener las etiquetas de los clusters\n",
        "etiquetas = kmeans.labels_\n",
        "\n",
        "# Obtener las coordenadas de los centroides\n",
        "centroides = kmeans.cluster_centers_\n",
        "\n",
        "# Crear una malla de puntos para visualizar las áreas de influencia\n",
        "h = .02  # tamaño del paso en la malla\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Predecir las etiquetas para cada punto en la malla\n",
        "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Visualizar las áreas de influencia y los datos\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(Z, interpolation='nearest', extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "           cmap='viridis', aspect='auto', origin='lower', alpha=0.3)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=np.concatenate((np.zeros(100), np.ones(100), np.full(100, 2))), cmap='viridis', s=50, alpha=0.6, edgecolors='w', label='Datos')\n",
        "plt.scatter(centroides[:, 0], centroides[:, 1], c='red', marker='x', s=200, linewidths=3, label='Centroides')\n",
        "plt.xlabel('Dimensión 1')\n",
        "plt.ylabel('Dimensión 2')\n",
        "plt.title('Clustering con K-means y Áreas de Influencia')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B0Ha5tPzP6dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grupos Difusos (Fuzzy Clustering)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Introducción al fuzzy clustering**: El fuzzy clustering es una técnica de agrupamiento que permite que los datos pertenezcan a más de un grupo (cluster) con diferentes grados de pertenencia. Este método es útil en situaciones donde los límites entre los grupos no están claramente definidos.\n",
        "- **Diferencias entre el clustering tradicional y el fuzzy clustering**: A diferencia del clustering tradicional (como K-means), donde cada punto pertenece exclusivamente a un cluster, el fuzzy clustering asigna a cada punto un grado de pertenencia a cada cluster, representado por un valor entre 0 y 1.\n",
        "- **Aplicaciones del fuzzy clustering en situaciones donde los individuos pueden pertenecer a más de un grupo**: Este método se utiliza en áreas como la segmentación de mercados, el análisis de imágenes médicas, y la biología, donde las características de los individuos pueden no pertenecer completamente a un solo grupo.\n",
        "\n",
        "**Ejemplo de Fuzzy Clustering con Fuzzy C-means en Python:**\n",
        "\n",
        "A continuación, presentamos un ejemplo práctico usando el algoritmo Fuzzy C-means para realizar clustering en un conjunto de datos generado aleatoriamente.\n",
        "\n",
        "**Código Python (Fuzzy C-means):**"
      ],
      "metadata": {
        "id": "cZ6hXBAAYO-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzy-c-means"
      ],
      "metadata": {
        "id": "xIBHkTOERStc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fcmeans import FCM\n",
        "\n",
        "# Generar datos de tres subpoblaciones normales bidimensionales\n",
        "np.random.seed(42)  # Fijar la semilla para reproducibilidad\n",
        "mu1 = [5, 5]\n",
        "sigma1 = [[1, 0.5], [0.5, 1]]\n",
        "mu2 = [8, 8]\n",
        "sigma2 = [[1, -0.5], [-0.5, 1]]\n",
        "mu3 = [5, 10]\n",
        "sigma3 = [[1, 0.5], [0.5, 1]]\n",
        "\n",
        "X1 = np.random.multivariate_normal(mu1, sigma1, 100)\n",
        "X2 = np.random.multivariate_normal(mu2, sigma2, 100)\n",
        "X3 = np.random.multivariate_normal(mu3, sigma3, 100)\n",
        "X = np.concatenate((X1, X2, X3))\n",
        "\n",
        "# Etiquetas de clases reales\n",
        "real_labels = np.concatenate((np.zeros(100), np.ones(100), np.full(100, 2)))\n",
        "\n",
        "# Ajustar un modelo Fuzzy C-means con tres clusters\n",
        "fcm = FCM(n_clusters=3, random_state=42)\n",
        "fcm.fit(X)\n",
        "\n",
        "# Obtener las probabilidades de pertenencia a los clusters\n",
        "probabilidades = fcm.u\n",
        "\n",
        "# Obtener las coordenadas de los centroides\n",
        "centroides = fcm.centers\n",
        "\n",
        "# Identificar la clase dominante y su probabilidad para cada punto\n",
        "dominant_class = np.argmax(probabilidades, axis=1)\n",
        "dominant_prob = np.max(probabilidades, axis=1)\n",
        "\n",
        "# Colores de las clases estimadas\n",
        "estimated_colors = ['r', 'g', 'b']\n",
        "# Símbolos para las clases reales\n",
        "real_symbols = ['o', '^', 's']\n",
        "\n",
        "# Visualizar los datos con las probabilidades de pertenencia\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Capa 1: Estimaciones con transparencia\n",
        "for j in range(X.shape[0]):\n",
        "    plt.scatter(X[j, 0], X[j, 1], color=estimated_colors[dominant_class[j]], alpha=dominant_prob[j], edgecolor=estimated_colors[dominant_class[j]], linewidths=0)\n",
        "\n",
        "# Capa 2: Clases reales con símbolos\n",
        "for label in np.unique(real_labels):\n",
        "    plt.scatter(X[real_labels == label, 0], X[real_labels == label, 1], facecolor='none', edgecolor='gray', marker=real_symbols[int(label)], s=100, linewidths=1, label=f'Clase Real {int(label) + 1}')\n",
        "\n",
        "plt.scatter(centroides[:, 0], centroides[:, 1], marker='x', s=200, linewidths=1, color='black', label='Centroides')\n",
        "plt.xlabel('Dimensión 1')\n",
        "plt.ylabel('Dimensión 2')\n",
        "plt.title('Fuzzy Clustering con C-means')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IeSDroHtYbTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}