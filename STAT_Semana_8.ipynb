{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUPN9zj3tI3SvErrd6FEHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/python-stats/blob/main/STAT_Semana_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Muestras y Poblaciones\n",
        "**Descripción:**\n",
        "\n",
        "- **Definición de población y muestra**: La población es el conjunto total de elementos que se desea estudiar, mientras que la muestra es un subconjunto representativo de la población.\n",
        "- **Diferencias entre parámetros muestrales y poblacionales**: Los parámetros muestrales se calculan a partir de la muestra y se utilizan para estimar los parámetros poblacionales.\n",
        "- **Importancia del muestreo en la inferencia estadística**: El muestreo permite hacer inferencias sobre la población sin necesidad de examinar a todos sus miembros.\n",
        "- **Ejemplos de cómo se utilizan las muestras para estimar valores poblacionales**: A través de la media muestral, varianza muestral, etc.\n",
        "\n",
        "**Código Python:**"
      ],
      "metadata": {
        "id": "EnMqEClbF8_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "806XfTAvEiBp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generar una población\n",
        "mu = 50\n",
        "sigma = 10\n",
        "poblacion = np.random.normal(mu,sigma, size=10000)\n",
        "\n",
        "# Obtener una muestra aleatoria de la población\n",
        "muestra = np.random.choice(poblacion, size=100, replace=False)\n",
        "\n",
        "# Calcular la media muestral\n",
        "media_muestral = np.mean(muestra)\n",
        "\n",
        "# Calcular la media poblacional\n",
        "media_poblacional = np.mean(poblacion)\n",
        "\n",
        "print(f\"Media muestral: {media_muestral}\")\n",
        "print(f\"Media poblacional: {media_poblacional}\")\n",
        "\n",
        "# Visualizar la distribución de la población y la muestra\n",
        "plt.hist(poblacion, bins=20, alpha=0.5, label='Población')\n",
        "plt.hist(muestra, bins=20, alpha=0.5, label='Muestra')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Valores')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución de la población y la muestra')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencia y Estimación Puntual\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Definición de inferencia estadística**: Proceso de deducir propiedades de una población a partir de una muestra.\n",
        "- **Introducción al concepto de estimador y estimación puntual**: Un estimador es una regla o fórmula para calcular una estimación de un parámetro poblacional. La estimación puntual se refiere a calcular un único valor como estimación del parámetro.\n",
        "- **Estimador de máxima verosimilitud para la media poblacional**: La media muestral es un estimador de máxima verosimilitud para la media poblacional.\n",
        "- **Estimación insesgada para la varianza poblacional**: La cuasivarianza muestral es un estimador insesgado de la varianza poblacional.\n",
        "\n",
        "**Código Python:**\n"
      ],
      "metadata": {
        "id": "0SR2UOkfLpbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar una muestra\n",
        "mu = 50\n",
        "sigma = 10\n",
        "muestra = np.random.normal(mu,sigma, size=100)\n",
        "\n",
        "# Calcular la media muestral (estimador de la media poblacional)\n",
        "media_muestral = np.mean(muestra)\n",
        "\n",
        "# Calcular la cuasivarianza muestral (estimador insesgado de la varianza poblacional)\n",
        "cuasivarianza_muestral = np.var(muestra, ddof=1)\n",
        "\n",
        "print(f\"Estimación de la media poblacional: {media_muestral}\")\n",
        "print(f\"Estimación de la varianza poblacional: {cuasivarianza_muestral}\")"
      ],
      "metadata": {
        "id": "nqMqf6tqLADE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esperanza Matemática\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "#### Definición de esperanza matemática:\n",
        "La esperanza matemática, también conocida como valor esperado, es una medida de la centralidad de una distribución de probabilidad. Se puede entender como el promedio ponderado de todos los posibles valores que puede tomar una variable aleatoria, donde cada valor está ponderado por su probabilidad de ocurrencia. Es un concepto fundamental en la teoría de la probabilidad y la estadística, ya que proporciona una medida del \"centro\" de la distribución.\n",
        "\n",
        "#### Interpretación de la esperanza matemática como el valor esperado de una variable aleatoria:\n",
        "La interpretación intuitiva de la esperanza matemática es que representa el valor promedio que se espera obtener si se repite un experimento aleatorio un gran número de veces. Por ejemplo, si lanzas una moneda justa muchas veces, la esperanza matemática del número de caras es el número total de lanzamientos multiplicado por la probabilidad de obtener cara en cada lanzamiento (que es 0.5).\n"
      ],
      "metadata": {
        "id": "tEDmKaGKPWNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Definir una variable aleatoria normal con media (mu) y desviación estándar (sigma)\n",
        "mu = 50\n",
        "sigma = 10\n",
        "X = norm(mu, sigma)\n",
        "\n",
        "# Calcular la esperanza matemática de X\n",
        "# Para una distribución normal, la esperanza matemática es igual a la media (mu)\n",
        "esperanza_X = X.expect()\n",
        "\n",
        "print(f\"Esperanza matemática de X: {esperanza_X}\")\n",
        "\n",
        "# Visualizar la función de densidad de probabilidad (PDF) de X\n",
        "# Generar un rango de valores de x desde el percentil 1% hasta el 99% de la distribución\n",
        "x = np.linspace(X.ppf(0.01), X.ppf(0.99), 100)\n",
        "\n",
        "# Calcular la PDF para cada valor de x\n",
        "pdf_values = X.pdf(x)\n",
        "\n",
        "# Crear la gráfica\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, pdf_values, 'r-', lw=2, alpha=0.6, label='Densidad de probabilidad (PDF)')\n",
        "\n",
        "# Dibujar una línea vertical en el valor de la esperanza matemática\n",
        "plt.axvline(esperanza_X, color='b', linestyle='dashed', linewidth=2, label='Esperanza matemática')\n",
        "\n",
        "# Añadir etiquetas y leyenda\n",
        "plt.xlabel('Valores')\n",
        "plt.ylabel('Densidad de Probabilidad')\n",
        "plt.title('Función de Densidad de Probabilidad de una Distribución Normal')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2loW3lVBNffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos de Mixtura\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Introducción a los modelos de mixtura**: Los modelos de mixtura son modelos probabilísticos que representan una población que puede estar compuesta por varias subpoblaciones, cada una con su propia distribución de probabilidad.\n",
        "- **Aplicaciones de los modelos de mixtura para identificar subpoblaciones dentro de una población**: Los modelos de mixtura se utilizan en diversas áreas como la biología, la economía y la ingeniería para identificar y analizar subgrupos dentro de una población global.\n",
        "- **Ejemplos de modelos de mixtura con distribuciones normales**: En muchos casos, se asume que las subpoblaciones siguen distribuciones normales, lo que facilita la identificación de estas subpoblaciones mediante modelos de mixtura gaussiana.\n",
        "\n",
        "**Código Python:**"
      ],
      "metadata": {
        "id": "_YdIoI65P2wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Generar datos de dos subpoblaciones normales\n",
        "mu1 = 20\n",
        "sigma1 = 5\n",
        "mu2 = 80\n",
        "sigma2 = 10\n",
        "X1 = np.random.normal(mu1, sigma1, size=100)\n",
        "X2 = np.random.normal(mu2, sigma2, size=100)\n",
        "X = np.concatenate((X1, X2))\n",
        "\n",
        "# Ajustar un modelo de mixtura gaussiana con dos componentes\n",
        "modelo = GaussianMixture(n_components=2)\n",
        "modelo.fit(X.reshape(-1, 1))\n",
        "\n",
        "# Obtener las etiquetas de las subpoblaciones\n",
        "etiquetas = modelo.predict(X.reshape(-1, 1))\n",
        "\n",
        "# Visualizar los datos con las etiquetas de las subpoblaciones\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(X, bins=30, alpha=0.5, label='Datos observados', density=True)\n",
        "\n",
        "# Generar valores para las campanas subyacentes\n",
        "x = np.linspace(np.min(X), np.max(X), 1000)\n",
        "logprob = modelo.score_samples(x.reshape(-1, 1))\n",
        "responsibilities = modelo.predict_proba(x.reshape(-1, 1))\n",
        "pdf_individual = responsibilities * np.exp(logprob[:, np.newaxis])\n",
        "pdf = pdf_individual.sum(1)\n",
        "\n",
        "# Visualizar las campanas de las subpoblaciones\n",
        "plt.plot(x, pdf, '-k', label='Mixtura Gaussiana')\n",
        "plt.plot(x, pdf_individual[:, 0], '--', label='Componente 1')\n",
        "plt.plot(x, pdf_individual[:, 1], '--', label='Componente 2')\n",
        "\n",
        "# Añadir puntos muestreados coloreados según las etiquetas\n",
        "colors = ['red', 'black']\n",
        "for label in np.unique(etiquetas):\n",
        "    plt.scatter(X[etiquetas == label], np.zeros_like(X[etiquetas == label]),\n",
        "                c=colors[label], label=f'Subpoblación {label + 1}', s=50, zorder=3)\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Valores')\n",
        "plt.ylabel('Densidad de probabilidad')\n",
        "plt.title('Modelo de Mixtura Gaussiana con Subpoblaciones')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_02QYGGPfnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering (Agrupamiento)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Introducción al clustering**: El clustering es una técnica de análisis de datos que busca agrupar un conjunto de objetos en subgrupos (clusters) de tal manera que los objetos en el mismo grupo (cluster) sean más similares entre sí que con los objetos de otros grupos.\n",
        "- **Diferentes tipos de algoritmos de clustering**:\n",
        "  - **K-means**: Un algoritmo que particiona los datos en K clusters, minimizando la variabilidad dentro de cada cluster.\n",
        "  - **Clustering jerárquico**: Construye una jerarquía de clusters que pueden ser visualizados mediante un dendrograma.\n",
        "  - **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: Agrupa puntos que están juntos en regiones de alta densidad y puede identificar outliers.\n",
        "- **Aplicaciones del clustering en diferentes áreas**: El clustering se utiliza ampliamente en marketing (segmentación de clientes), biología (clasificación de especies), biblioteconomía (organización de libros), imagenología médica (detección de estructuras), entre otros.\n",
        "\n",
        "**Ejemplo de Clustering con K-means en Python:**\n",
        "\n"
      ],
      "metadata": {
        "id": "tR8Jf-FDUXxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Generar datos de tres subpoblaciones normales bidimensionales\n",
        "mu1 = [7, 7]\n",
        "sigma1 = [[1, 0.5], [0.5, 1]]\n",
        "mu2 = [8, 8]\n",
        "sigma2 = [[1, -0.5], [-0.5, 1]]\n",
        "mu3 = [5, 10]\n",
        "sigma3 = [[1, 0.5], [0.5, 1]]\n",
        "\n",
        "X1 = np.random.multivariate_normal(mu1, sigma1, 100)\n",
        "X2 = np.random.multivariate_normal(mu2, sigma2, 100)\n",
        "X3 = np.random.multivariate_normal(mu3, sigma3, 100)\n",
        "X = np.concatenate((X1, X2, X3))\n",
        "\n",
        "# Ajustar un modelo k-means con tres clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Obtener las etiquetas de los clusters\n",
        "etiquetas = kmeans.labels_\n",
        "\n",
        "# Obtener las coordenadas de los centroides\n",
        "centroides = kmeans.cluster_centers_\n",
        "\n",
        "# Crear una malla de puntos para visualizar las áreas de influencia\n",
        "h = .02  # tamaño del paso en la malla\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Predecir las etiquetas para cada punto en la malla\n",
        "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Visualizar las áreas de influencia y los datos\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(Z, interpolation='nearest', extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "           cmap='viridis', aspect='auto', origin='lower', alpha=0.3)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=np.concatenate((np.zeros(100), np.ones(100), np.full(100, 2))), cmap='viridis', s=50, alpha=0.6, edgecolors='w', label='Datos')\n",
        "plt.scatter(centroides[:, 0], centroides[:, 1], c='red', marker='x', s=200, linewidths=3, label='Centroides')\n",
        "plt.xlabel('Dimensión 1')\n",
        "plt.ylabel('Dimensión 2')\n",
        "plt.title('Clustering con K-means y Áreas de Influencia')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B0Ha5tPzP6dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grupos Difusos (Fuzzy Clustering)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "- **Introducción al fuzzy clustering**: El fuzzy clustering es una técnica de agrupamiento que permite que los datos pertenezcan a más de un grupo (cluster) con diferentes grados de pertenencia. Este método es útil en situaciones donde los límites entre los grupos no están claramente definidos.\n",
        "- **Diferencias entre el clustering tradicional y el fuzzy clustering**: A diferencia del clustering tradicional (como K-means), donde cada punto pertenece exclusivamente a un cluster, el fuzzy clustering asigna a cada punto un grado de pertenencia a cada cluster, representado por un valor entre 0 y 1.\n",
        "- **Aplicaciones del fuzzy clustering en situaciones donde los individuos pueden pertenecer a más de un grupo**: Este método se utiliza en áreas como la segmentación de mercados, el análisis de imágenes médicas, y la biología, donde las características de los individuos pueden no pertenecer completamente a un solo grupo.\n",
        "\n",
        "**Ejemplo de Fuzzy Clustering con Fuzzy C-means en Python:**\n",
        "\n",
        "A continuación, presentamos un ejemplo práctico usando el algoritmo Fuzzy C-means para realizar clustering en un conjunto de datos generado aleatoriamente.\n",
        "\n",
        "**Código Python (Fuzzy C-means):**"
      ],
      "metadata": {
        "id": "cZ6hXBAAYO-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzy-c-means"
      ],
      "metadata": {
        "id": "xIBHkTOERStc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fcmeans import FCM\n",
        "\n",
        "# Generar datos de tres subpoblaciones normales bidimensionales\n",
        "np.random.seed(42)  # Fijar la semilla para reproducibilidad\n",
        "mu1 = [5, 5]\n",
        "sigma1 = [[1, 0.5], [0.5, 1]]\n",
        "mu2 = [8, 8]\n",
        "sigma2 = [[1, -0.5], [-0.5, 1]]\n",
        "mu3 = [5, 10]\n",
        "sigma3 = [[1, 0.5], [0.5, 1]]\n",
        "\n",
        "X1 = np.random.multivariate_normal(mu1, sigma1, 100)\n",
        "X2 = np.random.multivariate_normal(mu2, sigma2, 100)\n",
        "X3 = np.random.multivariate_normal(mu3, sigma3, 100)\n",
        "X = np.concatenate((X1, X2, X3))\n",
        "\n",
        "# Etiquetas de clases reales\n",
        "real_labels = np.concatenate((np.zeros(100), np.ones(100), np.full(100, 2)))\n",
        "\n",
        "# Ajustar un modelo Fuzzy C-means con tres clusters\n",
        "fcm = FCM(n_clusters=3, random_state=42)\n",
        "fcm.fit(X)\n",
        "\n",
        "# Obtener las probabilidades de pertenencia a los clusters\n",
        "probabilidades = fcm.u\n",
        "\n",
        "# Obtener las coordenadas de los centroides\n",
        "centroides = fcm.centers\n",
        "\n",
        "# Identificar la clase dominante y su probabilidad para cada punto\n",
        "dominant_class = np.argmax(probabilidades, axis=1)\n",
        "dominant_prob = np.max(probabilidades, axis=1)\n",
        "\n",
        "# Colores de las clases estimadas\n",
        "estimated_colors = ['r', 'g', 'b']\n",
        "# Símbolos para las clases reales\n",
        "real_symbols = ['o', '^', 's']\n",
        "\n",
        "# Visualizar los datos con las probabilidades de pertenencia\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Capa 1: Estimaciones con transparencia\n",
        "for j in range(X.shape[0]):\n",
        "    plt.scatter(X[j, 0], X[j, 1], color=estimated_colors[dominant_class[j]], alpha=dominant_prob[j], edgecolor=estimated_colors[dominant_class[j]], linewidths=0)\n",
        "\n",
        "# Capa 2: Clases reales con símbolos\n",
        "for label in np.unique(real_labels):\n",
        "    plt.scatter(X[real_labels == label, 0], X[real_labels == label, 1], facecolor='none', edgecolor='gray', marker=real_symbols[int(label)], s=100, linewidths=1, label=f'Clase Real {int(label) + 1}')\n",
        "\n",
        "plt.scatter(centroides[:, 0], centroides[:, 1], marker='x', s=200, linewidths=1, color='black', label='Centroides')\n",
        "plt.xlabel('Dimensión 1')\n",
        "plt.ylabel('Dimensión 2')\n",
        "plt.title('Fuzzy Clustering con C-means')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IeSDroHtYbTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPVQW__tYlsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFwqL2DEZ4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LN4yXuC4auGq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}